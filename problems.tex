\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[bulgarian]{babel}
\usepackage{amsmath}


\title{Курсова работа по Времеви редове}
\author{Йоана Левчева, ф.н. 26527}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section*{Задача 1}
\textbf{Отговорете на следните въпроси:}
\begin{flushleft}

\textbf{1. Какво представлява времевият ред?}
\begin{flushleft}
Времеви ред наричаме множество от наблюдения $\{ x_t \}$, всяко едно от които е регистрирано в определен момент от време $t$.
\end{flushleft}

\textbf{2. Опишете компонентите на времевия ред.}
\begin{flushleft}
Можем да представим процеса $\{X_t \}$ като реализация на процеса $X_t = m_t + s_t + Y_t$, където $m_t$ е компонента на тренда (бавно изменяща се функция), $s_t$ е функция с известен период $d$, която наричаме сезонна компонента и $Y_t$ е шумова компонента, която е стационарна.
\end{flushleft}

\textbf{3. Напишете формулата за автокорелация и обяснете какво измерва тя.}
\begin{flushleft}
Нека $X_t$ да е стационарен времеви ред. Автокорелационна формула на $\{X_t \}$ наричаме $$\rho_{X}(h) = \frac{\gamma_{X}(h)}{\gamma_{X}(0)} = Corr(X_{t+h}, X_t) = \frac{Cov(X_{t+h}, X_t)}{\sqrt{Var X_{t+h}Var X_t}},$$ където $\gamma_{X}(h) = Cov(X_{t+h}, X_t)$ е автоковариационната функция на $\{ X_t \}$. Автокорелацията представлява корелацията между величината и нейното закъснение за един или повече периода от време.
\end{flushleft}

\textbf{4. Какво е корелограма и за какво се използва тя?}
\begin{flushleft}
Корелограмата представлява графика на коефициентите на автокорелация за различни периоди на закъснение за дадения времеви ред. Показва изменението на автокорелацията с течение на времето. 
\end{flushleft}

\textbf{5. Всяко от следващите твърдения описва стационарен или нестационарен ред. Определете към кой тип бихте причислили всеки от тях.}
\begin{flushleft}
(а) ред, имащ тренд $\rightarrow$ нестационарен \\
(б) ред, за който функцията на средните стойности е периодична функция $\rightarrow$ нестационарен \\
(в) ред, не съдържащ нито подеми, нито спадове $\rightarrow$ стационарен \\
(г) Гаусов ред с нулево средно, чиито последователни стойности са некорелирани $\rightarrow$ стационарен \\
(д) ред, чиято функция на средните стойности остава постоянна във времето, а амплитудата му нараства с течение на времето $\rightarrow$ нестационарен
\end{flushleft}

\textbf{6. По-долу са описани няколко типа времеви редове: случайни, стационарни, съдържащи тренд, сезонни. Определете типа на всеки един от тях.}
\begin{flushleft}
(а) ред, чиито основни статистически свойства като средно и дисперсия остават постоянну във времето $\rightarrow$ стационарен \\
(б) времеви ред, чиито последователни стойности не са свързани един с друг $\rightarrow$ случаен \\
(в) значителен автокорелационен коефициент се появява за лагове, кратни на 4 $\rightarrow$ сезонен \\
(г) коефициентите на корелация значително се различават от нула за първите няколко лага, а после постепенно бавно клонят към нула с увеличаването на лага $\rightarrow$ съдържащ тренд \\
(д) коефициентите на автокорелация значително се различават от нула за първите няколко лага, а после експоненциално намаляват към нула с увеличаването на лага $\rightarrow$ стационарен \\
(е) стойностите на реда имат постоянна тенденция към наратсване $\rightarrow$ съдържащ тренд
\end{flushleft}

\textbf{7. В кой метод на прогнозиране стойността на изучаваната величина в текущия период се счита за прогноза за следващия?}
\begin{flushleft}
При наивните методи се предполага, че последният период най-добре прогнозира бъдещето. Тъй като на текущата стойност на времевия ред се приписва стопроцентна тежест, може да наречем наивната прогноза "прогноза без изменение": $$\widehat{X}_{t+1} = X_t$$.
\end{flushleft}

\textbf{8. В кой наивен метод на прогнозиране на наблюденията се приписват равни теглови коефициенти?}
\begin{flushleft}
В метода на простите средни за създаване на прогноза за следващия период се използва средната стойност на всички минали стойности на времевия ред. 
\end{flushleft}

\textbf{9. Какъв наивен метод на прогнозиране трябва да изберем, ако данните имат сезонност?}
\begin{flushleft}
Наивен метод при данни със сезонност, ако сезонните вариации са достатъчни силни, може да бъде: $$\widehat{X}_{t+1} = X_{t-d+1},$$ където $d$ е сезонната компонента.
\end{flushleft}

\end{flushleft}

\section*{Задача 2}
\begin{flushleft}

\textbf{1. Каква прогноза за периода 9 ще получим по метода на плаващото средно за 5 периода?}
\begin{flushleft}
$\widehat{X}_9 = \frac{X_8 + X_7 + X_6 + X_5 + X_4}{5} = \frac{216 + 219 + 220 + 225 + 226}{5} = 221.2$
\end{flushleft}

\textbf{2. Експоненциално изглаждане при $\alpha = 0.2$:}
\begin{flushleft}
$\widehat{Y}_2 = \alpha Y_1 + (1 - \alpha) \widehat{Y}_1 = 0.2\times200 + 0.8\times200 = 200$ \\
$\widehat{Y}_3 = \alpha Y_2 + (1 - \alpha) \widehat{Y}_2 = 0.2\times210 + 0.8\times200 = 202$ \\
$\widehat{Y}_4 = \alpha Y_3 + (1 - \alpha) \widehat{Y}_3 = 0.2\times215 + 0.8\times202 = 204.6$ \\
Грешка от прогнозата за период 3: $$e_3 = Y_3 - \widehat{Y}_3 = 215 - 202 = 13.$$
За прогнозата за период 4 можем да очакваме отново по-ниска стойност от действителната, което наистина е така. \\
$MAD = \frac{1}{n} \sum_{t=1}^{n} |Y_t - \widehat{Y}_t| = \frac{1}{3} \sum_{t=1}^{3} |Y_t - \widehat{Y}_t|$ \\
$MSE = \frac{1}{n} \sum_{t=1}^{n} (Y_t - \widehat{Y}_t)^2 = \frac{1}{3} \sum_{t=1}^{3} (Y_t - \widehat{Y}_t)^2$ \\
$MAPE = \frac{1}{n} \sum_{t=1}^{n} \frac{|Y_t - \widehat{Y}_t|}{Y_t} = \frac{1}{3} \sum_{t=1}^{3} \frac{|Y_t - \widehat{Y}_t|}{Y_t}$ \\
$MAPE = \frac{1}{n} \sum_{t=1}^{n} \frac{(Y_t - \widehat{Y}_t)}{Y_t} = \frac{1}{3} \sum_{t=1}^{3} \frac{(Y_t - \widehat{Y}_t)}{Y_t}$ \\

$MAD = \frac{1}{n} \sum_{t=1}^{n} |Y_t - \widehat{Y}_t| = \frac{1}{4} \sum_{t=1}^{4} |Y_t - \widehat{Y}_t|$ \\
$MSE = \frac{1}{n} \sum_{t=1}^{n} (Y_t - \widehat{Y}_t)^2 = \frac{1}{4} \sum_{t=1}^{4} (Y_t - \widehat{Y}_t)^2$ \\
$MAPE = \frac{1}{n} \sum_{t=1}^{n} \frac{|Y_t - \widehat{Y}_t|}{Y_t} = \frac{1}{4} \sum_{t=1}^{4} \frac{|Y_t - \widehat{Y}_t|}{Y_t}$ \\
$MAPE = \frac{1}{n} \sum_{t=1}^{n} \frac{(Y_t - \widehat{Y}_t)}{Y_t} = \frac{1}{4} \sum_{t=1}^{4} \frac{(Y_t - \widehat{Y}_t)}{Y_t}$ \\
\end{flushleft}

\textbf{3. Избиране на оптимална стойност на $\alpha$:}
\begin{flushleft}
За оптимална оценка на $\alpha$ един от методите използва минимизация на $MSE$. Последователно се изчисляват прогнози за $\alpha$, равно на 0.1, 0.2, ..., 0.9 и се пресмята $MSE$ за всяка една от тях. Стойността на $\alpha$, за която $MSE$ се окаже най-малка, се избира за по-нататъшно използване в прогнозите.
\end{flushleft}

\end{flushleft}

\section*{Задача 3}
\begin{flushleft}

\textbf{1.} вярно \\
\textbf{2.} вярно \\
\textbf{3.} вярно \\
\textbf{4.} грешно

\end{flushleft}

\section*{Задача 4}
\begin{flushleft}

\textbf{1. $X_t = a + bZ_0$}
\begin{flushleft}
$\mu(t) = EX_t = E(a + bZ_0) = E(a) + E(bZ_0) = a + bE(Z_0) = a,$ което не зависи от $t$. \\

\begin{flushleft}
$\gamma(h) = Cov(X_{t+h}, X_t) = Cov(a + bZ_0, a + bZ_0) = Var(a + bZ_0) = Var(a) + Var(bZ_0) = a^2 + b^2Var(Z_0) = a^2 + b^2 \sigma^2,$ което не зависи от $t$ за всяко $h$, тъй като по условие процесът е стационарен.. Следователно процесът е стационарен. 
\end{flushleft}

\end{flushleft}

\textbf{2. $X_t = a + bZ_t + cZ_{t-2}$}
\begin{flushleft}

\begin{flushleft}
$\mu(t) = EX_t = E(a + bZ_t + cZ_{t-2}) = E(a) + E(bZ_t) + E(cZ_{t-2}) = a + bE(Z_t) + cE(Z_{t-2}) = a,$ което не зависи от $t$. \\
\end{flushleft}

\begin{flushleft}
$\gamma(h) = Cov(X_{t+h}, X_t) = $ \\ 
$Cov(a + bZ_{t+h} + cZ_{t+h-2}, a + bZ_t + cZ_{t-2}) = $ \\
$Cov(bZ_{t+h}, bZ_{t}) +Cov(bZ_{t+h}, cZ_{t-2}) + Cov(cZ_{t+h-2}, bZ_t) + Cov(cZ_{t+h-2}, cZ_{t-2}) =$ \\ 
$b^2Cov(Z_{t+h}, Z_t) + bcCov(Z_{t+h}, Z_{t-2}) + bcCov(Z_{t+h-2}, Z_t) + c^2Cov(Z_{t+h-2}, Z_{t-2}) =$ \\
$b^2E(Z_{t+h}Z_t) + bcE(Z_{t+h}Z_{t-2}) + bcE(Z_{t+h-2}Z_t) + c^2E(Z_{t+h-2}Z_{t-2})$ \\
\end{flushleft}

Получаваме следните случаи: \\
\begin{flushleft}
1. $h = 0$: \\
$Cov(X_{t+0}, X_t) = b^2E(Z_{t}Z_t) + bcE(Z_{t}Z_{t-2}) + bcE(Z_{t-2}Z_t) + c^2E(Z_{t-2}Z_{t-2}) = (b^2 + c^2)\sigma^2$
\end{flushleft}

\begin{flushleft}
2. $h = 2$: \\
$Cov(X_{t+2}, X_t) = b^2E(Z_{t+2}Z_t) + bcE(Z_{t+2}Z_{t-2}) + bcE(Z_{t}Z_t) + c^2E(Z_{t}Z_{t-2}) = bc\sigma^2$
\end{flushleft}

\begin{flushleft}
3. $h = -2$: \\
$Cov(X_{t-2}, X_t) = b^2E(Z_{t-2}Z_t) + bcE(Z_{t-2}Z_{t-2}) + bcE(Z_{t-4}Z_t) + c^2E(Z_{t-4}Z_{t-2}) = bc\sigma^2$
\end{flushleft}

\begin{flushleft}
4. $|h| > 2$: \\
$Cov(X_{t+h}, X_t) = 0$ \\
Следователно $Cov(X_{t+0}, X_t)$ не зависи от $t$ за всяко $h$. Следователно процесът е стационарен.
\end{flushleft}

\end{flushleft}

\section*{Задача 5}
\begin{flushleft}
Даден е $\{X_t \}$ да е $AR(1)$ процес, определен от $X_t = \phi X_{t-1} + Z_t$, където $\{Z_t \}$ e $WN(0, \sigma^2), |\phi| < 1$ и $Z_t$ е некорелирано с $X_s$ за всяко $s < t$. Също така $\phi = 0.9$ и $\sigma^2 = 1$. \\
\end{flushleft}
\begin{flushleft}
$Var \overline{X}_4 = \frac{1}{4^2} \sum_{i=1}^{4} \sum_{j=1}^{4} Cov(X_i, X_j) = \frac{1}{4^2} \sum_{i-j=-4}^{4} (n - |i - j|)\gamma(i-j) = \frac{1}{4} \sum_{h=-4}^{4} (1 - \frac{|h|}{n})\gamma(h) = \frac{1}{4} \sum_{h=-4}^{4} (1 - \frac{|h|}{4}) \frac{\phi^{|h|} \sigma^2}{1 - \phi^2}$
\end{flushleft}

\section*{Задача 6}
\begin{flushleft}
Нека $\{X_t \}$ има функция на средните стойности $\mu_X(t) = \mu_X,$ която не зависи от $t$, тъй като по условие процесът е стационарен. И нека $\{X_t \}$ има автоковариационна функция $\gamma_X(h) = Cov(X_{t+h}, X_{t}),$ която не зависи от $t$ за всяко $h$, тъй като по условие процесът е стационарен.

\begin{flushleft}
Нека $\{Y_t \}$ има функция на средните стойности $\mu_Y(t) = \mu_Y,$ която не зависи от $t$, тъй като по условие процесът е стационарен. И нека $\{Y_t \}$ има автоковариационна функция $\gamma_Y(h) = Cov(Y_{t+h}, Y_{t}),$ която не зависи от $t$ за всяко $h$, тъй като по условие процесът е стационарен.
\end{flushleft}

\begin{flushleft}
Да пресметнем функцията на средните на процеса $\{X_t + Y_t \}$: \\
$$\mu_{XY} = E(X_t + Y_t) = E(X_t) + E(Y_t) = \mu_X + \mu_Y$$ и тъй като $\mu_X$ и $\mu_Y$ не зависят от $t$, то и $\mu_{XY}$ не зависи от $t$.
\end{flushleft}
\begin{flushleft}
Да пресметнем автоковариационната функцията на процеса $\{X_t + Y_t \}$: \\
$\gamma_{XY} = Cov(X_{t+h} + Y_{t+h}, X_t + Y_t) = Cov(X_{t+h}, X_{t}) + Cov(X_{t+h}, Y_t) + Cov(Y_{t+h}, X_t) + Cov(Y_{t+h}, Y_t) = \gamma_X + 0 + 0 + \gamma_Y = \gamma_X + \gamma_Y$ \\ 
и тъй като $\gamma_X$ и $\gamma_Y$ не зависят от $t$ за всяко $h$, то и $\gamma_{XY}$ не зависи от $t$ за всяко $h$. 
\end{flushleft}
Следователно процесът $\{X_t + Y_t \}$ е стационарен с автоковариационна функция, равна на сумата от автоковариационните функции на $\{X_t \}$ и $\{Y_t \}$.
\end{flushleft}

\section*{Задача 14}
\begin{flushleft}
Разглеждаме $$X_t = Z_t + 0.3Z_{t-1} - 0.4Z_{t-2},$$ където $\{Z_t \}$ e $WN(0, 1)$. Да запишем процеса във вида $$X_t = (1 + 0.3B - 0.4B^2)Z_t,$$ където $B$ е шифтовият оператор $B^jX_t = X_{t-j}$. По дефиниция процесът прилича на $ARMA(0, 2) = MA(2)$ процес. Нека разгледаме:

\begin{flushleft}
Авторегресионният полином $\phi(z) = 1$, тоест $\phi(z) \neq 0, \forall |z| \leq 1$. Следователно процесът е каузален, съответно и стационарен (защото $\phi(z) \neq 0, \forall |z| = 1$).
\end{flushleft}

\begin{flushleft}
$MA$ полиномът $\theta(z) = 1 + 0.3z - 0.4z^2 = 0,$ когато $z_1 = -1.25, |-1.25| > 1$ или $z_2 = 2, |2| > 1$. Тоест $\theta(z) \neq 0, \forall |z| < 1$. Следователно $X_t$ е обратим процес. Също така двата полинома нямат общи корени. Следователно можем да говорим за $ARMA(0, 2)$ процес или съответно $MA(2)$ процес.
\end{flushleft}

\begin{flushleft}
За автоковариационната функция на $MA(2)$ процеса (тъй като е линеен процес) имаме:

$
  \gamma(h) =
    \begin{cases}
      1^2 \sum_{j=0}^{2 - |h|} \theta_j \theta_{j+|h|}\text{, когато} |h| \leq 2 \\
      0, \text{когато} |h| > 2
    \end{cases}       
$ \\
където $\theta_0 = 1, \theta_1 = 0.3, \theta_2 = -0.4$.
\end{flushleft}
\end{flushleft}

\section*{Задача 15}

\textbf{1. $X_t + 0.2X_{t-1} - 0.48X_{t-2} = Z_t$}
\begin{flushleft}
Да запишем процеса във вида $$(1 + 0.2B - 0.48B^2)X_t = Z_t,$$ където $B$ е шифтовият оператор $B^j X_t = X_{t-j}$. По дефиниция процесът прилича на $ARMA(2, 0) = AR(2)$ процес. Нека разгледаме:

\begin{flushleft}
Авторегресионният полином $\phi(z) = 1 + 0.2z - 0.48z^2$, когато $z_1 = -1.25, |-1.25| > 1$ или $z_2 = 1.66, |1.66| > 1$, тоест $\phi(z) \neq 0, \forall |z| \leq 1$. Следователно процесът е каузален, съответно и стационарен (защото $\phi(z) \neq 0, \forall |z| = 1$).
\end{flushleft}

\begin{flushleft}
$MA$ полиномът $\theta(z) = 1$. Тоест $\theta(z) \neq 0, \forall |z| < 1$. Следователно $X_t$ е обратим процес. Също така двата полинома нямат общи корени. Следователно можем да говорим за $ARMA(2, 0)$ процес или съответно $AR(2)$ процес.
\end{flushleft}

\begin{flushleft}
$\{X_t \}$ е каузален процес, за който следователно имаме, че $X_t = \sum_{j=0}^{\infty}\psi_jZ_{t-j}, \forall t$ и: \\
$\psi_0 = 1$ \\
$\psi_1 = \theta_1 + \psi_0 \phi_1 = 0 + 1 \times (-0.2) = -0.2$ \\
$\psi_2 = \theta_2 + \psi_1 \phi_1 + \psi_0 \phi_2 = 0 + (-0.2) \times (-0.2) + 1 \times 0.48 = (-0.2)^2 + 0.48$ \\
... \\
$\psi_j = \sum_{k=1}^{2} \phi_k \psi_{j-k} + \theta_j = \phi_1 \psi_{j-1} + \phi_2 \psi_{j-2} = (-0.2)\psi_{j-1} + 0.48\psi_{j-2}, j = 2, 3, ...$ \\
\end{flushleft}

\end{flushleft}

\end{flushleft}
\end{document}
